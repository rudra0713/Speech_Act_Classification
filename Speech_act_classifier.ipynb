{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator, ReversibleField, TabularDataset, Iterator\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import random\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t': ['المباراه', 'القادمه', 'HASH', 'x', 'HASH', 'الجوله', 'الاخيره', 'من', 'المجموعه', 'ال', 'NUM', 'تصفيات', 'كاس', 'العالم', 'NUM', 'روسيا', 'ترتيب', 'مصر', 'المركز', 'الاول', 'NUM', 'نقطه', 'تم', 'حسم', 'التاهل', 'للمونديال', 'غدا', 'الساعه', 'NUM', 'NUM', 'ع', 'قناه', 'بين', 'سبورت', 'NUM', 'توقعاتكم', 'ل', 'نتيجه', 'الماتش', 'NUM', 'URL\\n'], 'l': 0}\n",
      "{'t': ['هل', 'هذه', 'هي', 'سياسه', 'خارجيه', 'لدوله', 'تحترم', 'نفسها', 'والاخرين', 'HASH', 'عدوان', 'وحصار', 'ل', 'NUM', 'سنوات', 'HASH', 'قمع', 'حراك', 'شعبها', 'المسالم', 'المطالب', 'بالمساواه', 'والعداله', 'HASH', 'دعموا', 'الارهاب', 'وارسلوا', 'المال', 'والسلاح', 'والانتحاريين', 'HASH', 'حصار', 'ومحاوله', 'فرض', 'الوصايه', 'والان', 'HASH', 'محاوله', 'فرض', 'وصايه', 'علني\\n'], 'l': 2}\n",
      "{'t': ['ومع', 'السيسي', 'و', 'بشار', 'و', 'ايران', 'و', 'بن', 'زايد', 'و', 'والا', 'خليفه', 'و', 'روافض', 'العراق', 'و', 'حفتر', 'و', 'علي', 'صالح', 'كل', 'طواغيت', 'العرب', 'العلاقات', 'عسل', 'علي', 'سمن\\n'], 'l': 2}\n",
      "cpu\n",
      "<class 'torchtext.data.iterator.BucketIterator'>\n",
      "Train:\n",
      "\n",
      "[torchtext.data.batch.Batch of size 2]\n",
      "\t[.t]:[torch.LongTensor of size 15x2]\n",
      "\t[.l]:[torch.LongTensor of size 2]\n",
      "dev:\n",
      "\n",
      "[torchtext.data.batch.Batch of size 2]\n",
      "\t[.t]:[torch.LongTensor of size 41x2]\n",
      "\t[.l]:[torch.LongTensor of size 2]\n"
     ]
    }
   ],
   "source": [
    "TWEET = Field()\n",
    "LABEL = Field(sequential=False, use_vocab=False)\n",
    "\n",
    "fields = {'tweet_50': ('t', TWEET), 'label_sa': ('l', LABEL)}\n",
    "\n",
    "train_data, valid_data, test_data = TabularDataset.splits(\n",
    "                                        path = 'ArSAS/json',\n",
    "                                        train = 'train_final.json',\n",
    "                                        validation = 'dev_final.json',\n",
    "                                        test = 'test_final.json',\n",
    "                                        format = 'json',\n",
    "                                        fields = fields\n",
    ")\n",
    "\n",
    "print(vars(train_data[0]))\n",
    "print(vars(valid_data[0]))\n",
    "print(vars(test_data[0]))\n",
    "TWEET.build_vocab(train_data)\n",
    "LABEL.build_vocab(train_data)\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), sort=False, batch_size= BATCH_SIZE, device=device)\n",
    "print(type(train_iterator))\n",
    "\n",
    "print('Train:')\n",
    "for batch in train_iterator:\n",
    "    print(batch)\n",
    "    break\n",
    "\n",
    "print('dev:')\n",
    "for batch in valid_iterator:\n",
    "    print(batch)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, query_dim, key_dim, value_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.scale = 1. / math.sqrt(query_dim)\n",
    "\n",
    "    def forward(self, query, keys, values):\n",
    "        # Query = Hidden\n",
    "        # hidden dim => (batch size, enc_hid_dim)\n",
    "        # Query = [BxQ]\n",
    "        # Keys = [TxBxK]\n",
    "        # Values = [TxBxV]\n",
    "        # Outputs = a:[TxB], lin_comb:[BxV]\n",
    "\n",
    "        # Here we assume q_dim == k_dim (dot product attention)\n",
    "\n",
    "        query = query.unsqueeze(1) # [BxQ] -> [Bx1xQ]\n",
    "        keys = keys.transpose(0,1).transpose(1,2) # [TxBxK] -> [BxKxT]\n",
    "        energy = torch.bmm(query, keys) # [Bx1xQ]x[BxKxT] -> [Bx1xT]\n",
    "        energy = F.softmax(energy.mul_(self.scale), dim=2) # scale, normalize\n",
    "\n",
    "        values = values.transpose(0,1) # [TxBxV] -> [BxTxV]\n",
    "        linear_combination = torch.bmm(energy, values).squeeze(1) #[Bx1xT]x[BxTxV] -> [BxV]\n",
    "        return energy, linear_combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, attention, input_dim, emb_dim, enc_hid_dim, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dropout = dropout\n",
    "        self.attention=attention\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, num_layers= 1, bidirectional=True)\n",
    "        self.linear = nn.Linear(enc_hid_dim*2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        # input dim => (src_sent_len, batch_size)\n",
    "        print(\"input shape \", input)\n",
    "        embed = self.dropout(self.embedding(input))\n",
    "        \n",
    "\n",
    "        # embed dim => (src_sent_len, batch_size, emb_dim)\n",
    "        outputs, hidden = self.rnn(embed)\n",
    "        print(\"outputs \", outputs)\n",
    "        print(\"....\")\n",
    "        print(\"hidden \", hidden)\n",
    "        # outputs dim => (src_sent_len, batch size, enc_hid_dim * num directions)\n",
    "        # hidden dim => (number of layers * number of directions, batch size, enc_hid_dim)\n",
    "        hidden = torch.cat((hidden[-2, : , :], hidden[-1, :, :]), dim = 1)\n",
    "        # hidden[-2, :, :] reduces 3d to 2d tensor since first dimension is now fixed, so dim = 1 is the last dimension\n",
    "        # hidden dim => (batch size, enc_hid_dim)\n",
    "\n",
    "\n",
    "        energy, attn_output = self.attention(hidden, outputs, outputs)\n",
    "        predictions = self.linear(attn_output)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_act_labels = ['Assertion', 'Recommendation', 'Expression', 'Question', 'Request', 'Miscellaneous']\n",
    "\n",
    "\n",
    "INPUT_DIM = len(TWEET.vocab)\n",
    "OUTPUT_DIM = len(speech_act_labels) - 1  # no miscellaneous class\n",
    "ENC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "ATTN_DIM = 500\n",
    "\n",
    "attn = Attention(ATTN_DIM, ATTN_DIM, ATTN_DIM)\n",
    "model = Encoder(attn, INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, OUTPUT_DIM, ENC_DROPOUT).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# pad_idx = TRG.vocab.stoi['<pad>']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        print(\"train iterator \", i)\n",
    "        src = batch.t\n",
    "        trg = batch.l\n",
    "#         print(\"src\")\n",
    "#         print(src)\n",
    "#         print(\"target\")\n",
    "#         print(trg)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src)\n",
    "        sys.exit(0)\n",
    "#         print(\"output after seq2seq\")\n",
    "#         print(output)\n",
    "#         print(output.shape)\n",
    "        #trg = [sent len, batch size]\n",
    "        #output = [sent len, batch size, output dim]\n",
    "        \n",
    "        #reshape to:\n",
    "        #trg = [(sent len - 1) * batch size]\n",
    "        #output = [(sent len - 1) * batch size, output dim]\n",
    "        loss = criterion(output, trg)\n",
    "        print(\"loss \", loss)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, testing):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    ground_truth, classification = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.t\n",
    "            trg = batch.l\n",
    "            \n",
    "            output = model(src) #turn off teacher forcing\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            if testing:\n",
    "                \n",
    "                for j, ind_output in enumerate(output):\n",
    "                    max_index = ind_output.max(0)[1]\n",
    "                    classification.append(max_index.item())\n",
    "                    ground_truth.append(trg[j].item())\n",
    "                    \n",
    "    if testing:\n",
    "        print(\"trg \", trg.shape)\n",
    "        print(\"classification \", len(classification))\n",
    "        precision, recall, fscore, support = score(np.array(ground_truth), classification)\n",
    "        print(\"Detailed evaluation:\")\n",
    "        print('precision: {}'.format(precision))\n",
    "        print('recall: {}'.format(recall))\n",
    "        print('fscore: {}'.format(fscore))\n",
    "        print('support: {}'.format(support))\n",
    " \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "train iterator  0\n",
      "input shape  tensor([[26376,   191],\n",
      "        [   11,  2072],\n",
      "        [ 7605,   481],\n",
      "        [ 4295,    39],\n",
      "        [   70, 15346],\n",
      "        [   69,    13],\n",
      "        [19660, 17791],\n",
      "        [ 1931, 27191],\n",
      "        [ 9831,  5142],\n",
      "        [18853, 19563],\n",
      "        [    2,     1],\n",
      "        [   43,     1],\n",
      "        [ 4339,     1],\n",
      "        [    6,     1],\n",
      "        [  696,     1],\n",
      "        [14833,     1],\n",
      "        [   11,     1],\n",
      "        [ 4685,     1],\n",
      "        [23431,     1],\n",
      "        [   19,     1],\n",
      "        [  129,     1],\n",
      "        [ 1975,     1],\n",
      "        [   11,     1],\n",
      "        [  723,     1],\n",
      "        [  129,     1],\n",
      "        [ 5241,     1],\n",
      "        [ 2048,     1],\n",
      "        [   11,     1],\n",
      "        [  882,     1],\n",
      "        [    6,     1],\n",
      "        [  377,     1],\n",
      "        [ 3273,     1],\n",
      "        [  292,     1],\n",
      "        [ 6660,     1],\n",
      "        [  163,     1],\n",
      "        [   13,     1],\n",
      "        [  182,     1]])\n",
      "outputs  tensor([[[-0.3701, -0.2110, -0.4401,  ...,  0.3120,  0.0869, -0.1061],\n",
      "         [ 0.3813, -0.1451,  0.3690,  ..., -0.2545,  0.1398, -0.4544]],\n",
      "\n",
      "        [[ 0.2844, -0.1844, -0.5066,  ...,  0.0847,  0.4226,  0.2304],\n",
      "         [-0.0996, -0.2066,  0.0745,  ..., -0.0450, -0.0957, -0.4925]],\n",
      "\n",
      "        [[ 0.3654,  0.0344, -0.1897,  ...,  0.1428,  0.0884,  0.4777],\n",
      "         [-0.2743, -0.1841, -0.1075,  ..., -0.4197,  0.0246, -0.6192]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.5329, -0.2556, -0.2476,  ..., -0.0260, -0.0770, -0.0663],\n",
      "         [ 0.1222, -0.2036,  0.2991,  ...,  0.2044,  0.2266,  0.3375]],\n",
      "\n",
      "        [[ 0.5414, -0.1495, -0.2761,  ..., -0.0336, -0.0255, -0.2508],\n",
      "         [ 0.0232, -0.3543,  0.2248,  ...,  0.1592, -0.2518,  0.3810]],\n",
      "\n",
      "        [[ 0.2643, -0.4283, -0.3106,  ...,  0.2750,  0.3110,  0.0562],\n",
      "         [ 0.2037,  0.0442,  0.1822,  ..., -0.0882,  0.2031,  0.3731]]],\n",
      "       grad_fn=<CatBackward>)\n",
      "....\n",
      "hidden  tensor([[[ 0.2643, -0.4283, -0.3106,  ..., -0.1006, -0.1503, -0.1532],\n",
      "         [ 0.2037,  0.0442,  0.1822,  ..., -0.7027,  0.2942, -0.1460]],\n",
      "\n",
      "        [[-0.4625, -0.1224,  0.1793,  ...,  0.3120,  0.0869, -0.1061],\n",
      "         [-0.3954,  0.4331, -0.1300,  ..., -0.2545,  0.1398, -0.4544]]],\n",
      "       grad_fn=<ViewBackward>)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "CLIP = 0.001\n",
    "SAVE_DIR = 'models'\n",
    "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'sa_weights_50.pt')\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "if not os.path.isdir(f'{SAVE_DIR}'):\n",
    "    os.makedirs(f'{SAVE_DIR}')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(\"epoch \", epoch)\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion, False)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:03} | Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f} | Val. Loss: {valid_loss:.3f} | Val. PPL: {math.exp(valid_loss):7.3f} |')\n",
    "    print(f'| Epoch: {epoch+1:03} | Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}  |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion, True)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
